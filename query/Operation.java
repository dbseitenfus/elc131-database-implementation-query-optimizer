/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package ibd.query;

import ibd.query.binaryop.BinaryOperation;
import ibd.query.binaryop.join.Join;
import ibd.query.lookup.LookupFilter;
import ibd.query.lookup.NoLookupFilter;
import ibd.table.prototype.column.Column;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

/**
 * An operation in this context is defined as a data transformation step within
 * a tree structure, which serves as a query execution plan. Each node within
 * the tree, representing an operation, plays a specific role in the process of
 * data access and transformation:
 *
 * - Source operations: These are leaf nodes that directly interact with data
 * sources, initiating data flow. - Unary operations: Nodes that perform
 * transformations using data from a single preceding operation. - Binary
 * operations: Nodes that manipulate data received from two preceding
 * operations.
 *
 * Data flows from the leaf nodes to the root, with each node processing
 * incoming tuples from underlying operations and producing new tuples as a
 * result of its transformation. The leaf nodes, being source operations, are
 * the entry points for data sources. The root node represents the entire query,
 * aggregating and finalizing the data transformation process.
 *
 * Regarding tuple formation: - Source operations produce tuples consisting of a
 * single row from their respective data sources. - Unary operations produce
 * tuples that contain the same number of rows as the tuples provided by the
 * underlying operation. - Binary operations, such as joins, produce tuples
 * where the number of rows is the sum of the rows from the two input tuples
 * provided by the connected children.
 *
 * Queries can be executed at any node; which redirects the request to the
 * relevant operations below it, leveraging the hierarchical structure to
 * execute the query across the various transformation stages.
 *
 * @author Sergio
 */
public abstract class Operation {

    /**
     * the data sources accessed directly or indirectly by this operation. This
     * information is useful to identify which row from a returning tuple comes
     * from a specific data source. Given the refered data source name, the row
     * can be located and used by the transformation process.
     */
    protected ReferedDataSource[] dataSources;

    /**
     * The `processedOperations` variable contains a list of all operations that
     * execute prior to the current operation. This list provides access to all
     * the tuples and their respective rows generated by these preceding
     * operations. Such accessibility enables the use of reference columns,
     * analogous to correlated variables in SQL. In SQL, these variables are
     * often employed in filters within subqueries. Similarly, in our query
     * engine, this feature allows the creation of dynamic filters that operate
     * on data produced by the already executed operations, enabling complex
     * data querying scenarios and deeper data interaction across different
     * stages of the query execution plan.
     */
    protected List<Operation> processedOperations = null;

    /**
     * the parent operation, if one exists
     */
    protected Operation parentOperation;

    /**
     * the operation is ready to call prepare. It needs to have the data sources
     * set immediately prior to calling the prepare method.
     */
    protected boolean isReady = false;

    /**
     * The index of the first tuple to retrieve. Must be a non-negative integer.
     * All tuples before the index are computed but not retrieved.
     */
    protected int startingTuple = -1;

    /**
     * The number of tuples to read from the starting tuple. Must be a positive
     * integer.
     */
    protected int tuplesToRead = -1;

    /**
     * Indicates if this operator has filters delegated from its parent that
     * need to be performed.
     */
    protected boolean hasDelegatedFilters = true;

    /**
     * Sets information regarding the tuples that need to be retrieved, based on
     * the index of the computed tuples
     *
     * @param startingTuple: The index of the first tuple to retrieve. Must be a
     * non-negative integer.
     * @param tuplesToRead The number of tuples to read from the starting tuple.
     * Must be a positive integer.
     */
    public void setPageInfo(int startingTuple, int tuplesToRead) {
        this.startingTuple = startingTuple;
        this.tuplesToRead = tuplesToRead;
    }

    /**
     * @return The index of the first tuple to retrieve.
     */
    public int getStartingTuple() {
        return startingTuple;
    }

    /**
     * @return The number of tuples to read from the starting tuple.
     */
    public int getTuplesToRead() {
        return tuplesToRead;
    }

    /**
     * @return the data sources accessed directly or indirectly by this
     * operation
     * @throws Exception
     */
    public ReferedDataSource[] getDataSources() throws Exception {
        return dataSources;
    }

    /**
     * Prepares this operation for query answering performing one-time setup
     * commands. The preparation involves: - setting up static variables;
     * setting array indexes to row columns; opening data sources, if any;
     * preparing the underlying operations, if any.
     *
     * @throws Exception
     */
    public void prepare() throws Exception {
        checkFilters();
    }

    /**
     *
     * @return a boolean indicating if this operation needs to perform filters that come from its parent.
     */
    public boolean hasDelegatedfilters(){
        return hasDelegatedFilters;
    }
    
    /**
     * Sets the hasDelegatedFilters variable. The variable is true if this
     * operator needs to perform filters that come from its parent
     *
     * @throws Exception
     */
    private void checkFilters() throws Exception {

        hasDelegatedFilters = false;
        if (parentOperation == null) {
            return;
        }

        //if the parent operator has filters, we initially set it to true
        if (!(parentOperation.getFilters() instanceof NoLookupFilter)) {
            hasDelegatedFilters = true;
        }
        if (parentOperation instanceof BinaryOperation) {
            BinaryOperation bop = (BinaryOperation) parentOperation;
            if (bop.useLeftSideLookups()) {
                //the parent binary operator delegates filters to the right side, but this operator is not on the right side
                if (bop.getLeftOperation().equals(this)) {
                    hasDelegatedFilters = false;
                }
            } else {
                //the parent binary operator does not delegates filters to the right side
                //hasFilters = false;
            }

        }

    }

    /**
     *
     * @return
     */
    public LookupFilter getDelegatedFilters() {
        if (hasDelegatedFilters) {
            return parentOperation.getFilters();
        }
        return new NoLookupFilter();
    }

    /**
     * Retrieves the filters generated by this operation. The filters created by
     * an operation are not processed internally by the same operation. Instead,
     * they are delegated to one of its direct underlying operations in the
     * query execution tree. Operations such as 'Filter' and 'NestedLoopJoin'
     * are examples of operations that can create such filters. This setup
     * allows for modular and efficient filtering mechanisms where processing is
     * delegated to appropriate subcomponents of the query plan.
     *
     * @return the filters.
     */
    public LookupFilter getFilters() {
        return new NoLookupFilter();
    }

    ;
    
    

    /**
     * Sets the parent operation
     *
     * @param op
     */
    public void setParentOperation(Operation op) {
        parentOperation = op;
    }

    /**
     * @return the parent operation
     */
    public Operation getParentOperation() {
        return parentOperation;
    }

    /**
     * Returns the index of the row refered by an alias. if no alias is
     * provided, the first row is selected (index 0)
     *
     * @param tableName the alias of the table
     * @return the found index or -1 if no index was found
     * @throws Exception
     */
    private int getRowIndex(String tableName) throws Exception {
        if (tableName == null) {
            return 0;
        } else {
            ReferedDataSource[] dataSources_ = getDataSources();
            for (int i = 0; i < dataSources_.length; i++) {
                if (dataSources_[i].alias.equals(tableName)) {
                    return i;
                }

            }
        }
        return -1;
    }

//    public int getColumnIndex(int rowIndex, String Column) throws Exception {
//
//        ReferedDataSource[] dataSources_ = getDataSources();
//        Column col = dataSources_[rowIndex].prototype.getColumn(Column);
//        return col.index;
//    }
    /**
     * Sets the array indexes that identify the most recent value of a
     * specified column, taking into account tuples from previously processed
     * operations. This method operates in three distinct steps:
     *
     * 1. **Locate Operation Index**: Identify the index of the processed
     * operation within the hierarchy that contains the relevant data source.
     * This indirectly leads to the most recent tuple generated by this
     * operation.
     *
     * 2. **Locate Data Source Index**: The identified tuple is composed of
     * rows, each originating from a data source. The second step determines the
     * index of the proper data source, which indirectly leads to the specific
     * row from which the data originates.
     *
     * 3. **Locate Column Index**: The identified data source is composed of
     * columns. The third step finds the index of the proper column within the
     * data source. This index indirectly corresponds to the specific column
     * value (field) within the row.
     *
     * With these three indexes (operation, data source, and column) we can
     * accurately locate the desired column value during query execution,
     * ensuring that the most recent data from an already processed operation is
     * accessed.
     *
     * @param columnDescriptor
     * @throws Exception
     */
    public void setColumnLocationFromProcessedOperations(ColumnDescriptor columnDescriptor) throws Exception {

        for (int i = 0; i < processedOperations.size(); i++) {
            Operation processedOperation = processedOperations.get(i);
            processedOperation.setColumnLocation(columnDescriptor);
            ColumnLocation auxColumnLocation = columnDescriptor.getColumnLocation();
            if (auxColumnLocation != null) {
                auxColumnLocation.tupleIndex = i;
                return;
            }
        }

    }

    /**
     * Sets the array indexes that identify the most recent value of a
     * specified column, taking into account data from the tuple under
     * processing by this operation. This method operates in two distinct steps:
     *
     * 1. **Locate Data Source Index**: The tuple under processing is composed
     * of rows, each originating from a data source. The first step determines
     * the index of the proper data source, which indirectly leads to the
     * specific row from which the data originates.
     *
     * 2. **Locate Column Index**: The identified data source is composed of
     * columns. The second step finds the index of the proper column within the
     * data source. This index indirectly corresponds to the specific column
     * value (field) within the row.
     *
     * With these two indexes (data source and column) we can accurately locate
     * the desired column value during query execution, ensuring that the most
     * recent data is accessed.
     *
     * @param columnDescriptor
     * @throws Exception
     */
    public void setColumnLocation(ColumnDescriptor columnDescriptor) throws Exception {

        ColumnLocation colLoc = new ColumnLocation();

        if (columnDescriptor.getTableName() == null) {
            colLoc.tupleIndex = 0;
            colLoc.rowIndex = 0;
            ReferedDataSource[] dataSources_ = getDataSources();
            Column col = dataSources_[0].prototype.getColumn(columnDescriptor.getColumnName());
            colLoc.colIndex = col.index;
            columnDescriptor.setColumnLocation(colLoc);
        } else {
            int rowIndex = getRowIndex(columnDescriptor.getTableName());
            if (rowIndex != -1) {
                Column col = getDataSources()[rowIndex].prototype.getColumn(columnDescriptor.getColumnName());
                colLoc.rowIndex = rowIndex;
                colLoc.colIndex = col.index;
                columnDescriptor.setColumnLocation(colLoc);
            }
        }

    }

    /**
     * sets information about the data sources that are directly or indirectly
     * accessed by this operation. The information includes the source alias and
     * schema.
     *
     * @throws Exception
     */
    public abstract void setDataSourcesInfo() throws Exception;

    /**
     * Sets the list of operations that already have processed tuples before
     * this operation executes.
     */
    public void setProcessedOperations() {

        processedOperations = new ArrayList();

        Operation parent = getParentOperation();
        if (parent != null && parent.processedOperations != null) {
            List<Operation> processedOperations_ = parent.processedOperations;
            //the processing operations contains all processing operations of the parent node
            processedOperations.addAll(processedOperations_);
            if (parent instanceof Join) {
                Join join = (Join) parent;

                //if this is the right side of a nested loop join, the processing operations also contains the tuple that was produced by the left-side operation. 
                if (join.useLeftSideLookups() && join.getRightOperation().equals(this)) {
                    processedOperations.add(join.getLeftOperation());
                }
            }
        }
    }

    /**
     * Runs a query, using this operation to transform data and produce
     * resulting tuples.
     *
     * This method must be implemented by operations that actually produce
     * tuples as a result of their processing. Extensions can benefit from the
     * OperationIterator class that contains an overall code strucure already
     * defined, leaving only the tuple generation part to be implemented.
     *
     * @param processedTuples the tuples that come from operations already
     * processed. The rows from these tuples can be used by the unprocessed
     * operations, like for filtering.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @return an iterator containing the tuples that answer the query.
     */
    protected abstract Iterator<Tuple> lookUp_(List<Tuple> processedTuples, boolean withFilterDelegation);

    /**
     * Runs a query, using this operation to transform data and produce
     * resulting tuples. Avoid calling this method directly, as it depends on
     * some preparation settings. Use the method 'run' instead.
     *
     * @param processedTuples the tuples that come from operations already
     * processed. The rows from these tuples can be used by the unprocessed
     * operations, like for filtering.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @return an iterator containing the tuples that answer the query.
     */
    public Iterator<Tuple> lookUp(List<Tuple> processedTuples, boolean withFilterDelegation) {
        if (tuplesToRead != -1 && startingTuple != -1) {
            return pagedLookUp(processedTuples, withFilterDelegation, startingTuple, tuplesToRead);
        } else {
            return lookUp_(processedTuples, withFilterDelegation);
        }
    }

    /**
     * Runs a query, retrieving only the tuples that match the paging parameters
     * (startingTuple and tuplesToRead).
     *
     * @param processedTuples the tuples that come from operations already
     * processed.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @param startingTuple The index of the first tuple to retrieve. Must be a
     * non-negative integer.
     * @param tuplesToRead The number of tuples to read from the starting tuple.
     * Must be a positive integer.
     * @return an iterator containing the tuples that answer the query.
     */
    protected Iterator<Tuple> pagedLookUp(List<Tuple> processedTuples, boolean withFilterDelegation, int startingTuple, int tuplesToRead) {
        return new PagedOperationIterator(lookUp_(processedTuples, withFilterDelegation), startingTuple, tuplesToRead);
    }

    /**
     * Verifies if this operation produces resulting tuples.
     *
     * @param processedTuples the tuples that come from operations already
     * processed.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @return true if at least one tuple exists as a result of this operation.
     */
    public boolean exists(List<Tuple> processedTuples, boolean withFilterDelegation) {
        Iterator<Tuple> iterator = pagedLookUp(processedTuples, withFilterDelegation, 0, 1);
        return iterator.hasNext();
    }

    /**
     * Runs a query, using the tree below this operation to transform data and
     * produce resulting tuples.
     *
     * @return an iterator containing the tuples that answer the query
     * @throws java.lang.Exception
     */
    public Iterator<Tuple> run() throws Exception {
        //sets information from the data sources that are important during query execution
        setDataSourcesInfo();
        setProcessedOperations();

        //prepares the operations from the query tree
        prepare();

        //runs the query using with an empty list of processed operations and no delegated filters .
        return lookUp(new ArrayList(), false);
    }

    /**
     * Cleans up resources, if necessary, for the whole hierarchy starting from
     * this operation.
     *
     * @throws Exception
     */
    public abstract void close() throws Exception;

}
